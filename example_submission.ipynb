{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f7cc6f8-f9e4-43f3-b553-d01e072f4f00",
   "metadata": {},
   "source": [
    "# Financial Text Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be00b0-b946-474c-9c7c-234d83084e23",
   "metadata": {},
   "source": [
    "## Install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b637adb-0d48-4808-9123-af29e51a1144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting happytransformer\n",
      "  Downloading happytransformer-3.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.10/dist-packages (from happytransformer) (2.1.0+cu118)\n",
      "Collecting tqdm>=4.43 (from happytransformer)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.6/57.6 kB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting transformers<5.0.0,>=4.30.1 (from happytransformer)\n",
      "  Downloading transformers-4.38.1-py3-none-any.whl.metadata (131 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m131.1/131.1 kB\u001B[0m \u001B[31m6.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting datasets<3.0.0,>=2.13.1 (from happytransformer)\n",
      "  Downloading datasets-2.17.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting sentencepiece (from happytransformer)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting protobuf (from happytransformer)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting accelerate<1.0.0,>=0.20.1 (from happytransformer)\n",
      "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tokenizers<1.0.0,>=0.13.3 (from happytransformer)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting wandb (from happytransformer)\n",
      "  Downloading wandb-0.16.3-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (6.0.1)\n",
      "Collecting huggingface-hub (from accelerate<1.0.0,>=0.20.1->happytransformer)\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting safetensors>=0.3.1 (from accelerate<1.0.0,>=0.20.1->happytransformer)\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (3.9.0)\n",
      "Collecting pyarrow>=12.0.0 (from datasets<3.0.0,>=2.13.1->happytransformer)\n",
      "  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets<3.0.0,>=2.13.1->happytransformer)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets<3.0.0,>=2.13.1->happytransformer)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets<3.0.0,>=2.13.1->happytransformer)\n",
      "  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (2.31.0)\n",
      "Collecting xxhash (from datasets<3.0.0,>=2.13.1->happytransformer)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets<3.0.0,>=2.13.1->happytransformer)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets<3.0.0,>=2.13.1->happytransformer) (2023.4.0)\n",
      "Collecting aiohttp (from datasets<3.0.0,>=2.13.1->happytransformer)\n",
      "  Downloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->happytransformer) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->happytransformer) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->happytransformer) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->happytransformer) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->happytransformer) (2.1.0)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.30.1->happytransformer)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.9/40.9 kB\u001B[0m \u001B[31m9.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting Click!=8.0.0,>=7.1 (from wandb->happytransformer)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->happytransformer)\n",
      "  Downloading GitPython-3.1.42-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb->happytransformer)\n",
      "  Downloading sentry_sdk-1.40.5-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->happytransformer)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting setproctitle (from wandb->happytransformer)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->happytransformer) (68.2.2)\n",
      "Collecting appdirs>=1.4.3 (from wandb->happytransformer)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb->happytransformer) (1.16.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->happytransformer)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub (from accelerate<1.0.0,>=0.20.1->happytransformer)\n",
      "  Downloading huggingface_hub-0.20.2-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.20.1-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.20.0-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting fsspec[http]<=2023.10.0,>=2023.1.0 (from datasets<3.0.0,>=2.13.1->happytransformer)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.13.1->happytransformer) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.13.1->happytransformer) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.13.1->happytransformer) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.13.1->happytransformer) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0->happytransformer) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.13.1->happytransformer) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets<3.0.0,>=2.13.1->happytransformer)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets<3.0.0,>=2.13.1->happytransformer)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0->happytransformer) (1.3.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->happytransformer)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading happytransformer-3.0.0-py3-none-any.whl (24 kB)\n",
      "Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m280.0/280.0 kB\u001B[0m \u001B[31m4.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m536.7/536.7 kB\u001B[0m \u001B[31m7.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m15.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.3/78.3 kB\u001B[0m \u001B[31m19.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading transformers-4.38.1-py3-none-any.whl (8.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.5/8.5 MB\u001B[0m \u001B[31m35.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m294.6/294.6 kB\u001B[0m \u001B[31m46.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m51.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading wandb-0.16.3-py3-none-any.whl (2.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.2/2.2 MB\u001B[0m \u001B[31m61.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m97.9/97.9 kB\u001B[0m \u001B[31m26.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m116.3/116.3 kB\u001B[0m \u001B[31m21.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m166.4/166.4 kB\u001B[0m \u001B[31m39.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m330.1/330.1 kB\u001B[0m \u001B[31m67.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m64.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m195.4/195.4 kB\u001B[0m \u001B[31m41.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m38.3/38.3 MB\u001B[0m \u001B[31m72.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m774.0/774.0 kB\u001B[0m \u001B[31m84.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m113.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading sentry_sdk-1.40.5-py2.py3-none-any.whl (258 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m258.5/258.5 kB\u001B[0m \u001B[31m51.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m134.8/134.8 kB\u001B[0m \u001B[31m29.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.0/13.0 MB\u001B[0m \u001B[31m115.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m194.1/194.1 kB\u001B[0m \u001B[31m18.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m239.5/239.5 kB\u001B[0m \u001B[31m46.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.7/62.7 kB\u001B[0m \u001B[31m17.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m124.3/124.3 kB\u001B[0m \u001B[31m32.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m505.5/505.5 kB\u001B[0m \u001B[31m89.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m345.4/345.4 kB\u001B[0m \u001B[31m70.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m301.6/301.6 kB\u001B[0m \u001B[31m63.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: sentencepiece, pytz, appdirs, xxhash, tzdata, tqdm, smmap, setproctitle, sentry-sdk, safetensors, regex, pyarrow-hotfix, pyarrow, protobuf, multidict, fsspec, frozenlist, docker-pycreds, dill, Click, async-timeout, yarl, pandas, multiprocess, huggingface-hub, gitdb, aiosignal, tokenizers, GitPython, aiohttp, accelerate, wandb, transformers, datasets, happytransformer\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed Click-8.1.7 GitPython-3.1.42 accelerate-0.27.2 aiohttp-3.9.3 aiosignal-1.3.1 appdirs-1.4.4 async-timeout-4.0.3 datasets-2.17.1 dill-0.3.8 docker-pycreds-0.4.0 frozenlist-1.4.1 fsspec-2023.10.0 gitdb-4.0.11 happytransformer-3.0.0 huggingface-hub-0.20.3 multidict-6.0.5 multiprocess-0.70.16 pandas-2.2.1 protobuf-4.25.3 pyarrow-15.0.0 pyarrow-hotfix-0.6 pytz-2024.1 regex-2023.12.25 safetensors-0.4.2 sentencepiece-0.2.0 sentry-sdk-1.40.5 setproctitle-1.3.3 smmap-5.0.1 tokenizers-0.15.2 tqdm-4.66.2 transformers-4.38.1 tzdata-2024.1 wandb-0.16.3 xxhash-3.4.1 yarl-1.9.4\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython -m pip install --upgrade pip\u001B[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install happytransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd7651f-243b-4f39-959a-33fb6cae0d5e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45509706-bfa6-4b42-aa22-f54d20786337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datasets import load_dataset\n",
    "from happytransformer import HappyTextClassification, TCTrainArgs\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ac685-967a-4e79-9312-4b0d64a1880d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57322a7-a3df-4cf7-903f-e5f4b069432f",
   "metadata": {},
   "source": [
    "### Download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dc3b01f-e6bf-41fd-8dac-9fb9e0048d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e920eabb1747e5ae023c79998ab41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93aa6aaeb3784bfc8f4bcbd4d2ed567d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/859k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77c9b4b433c4d8caef69353aa311d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/217k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63770eb7546141589ab7cec67aa53f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846f9d5523d343de9dd17ba5615f9cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment\n",
    "dataset = load_dataset(\"zeroshot/twitter-financial-news-sentiment\")\n",
    "dataset = dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c077a82a-2a69-4bd5-9f0a-cebe39ffce11",
   "metadata": {},
   "source": [
    "### Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc50fa4-2fab-47f5-9e58-6b52930962bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 9543\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2388\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e31bf5cd-b73b-477d-8a4e-c955d74e4501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Stocks - Tiffany, Disney, Tesla Rise Premarket; Uber Falls', 'label': 2}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0257c8ce-c775-4393-8b23-52537556001a",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42adf002-6fc0-4a5c-aff8-41cdf9575091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 9000 cases for training \n",
    "train_data = dataset[\"train\"][:9000]\n",
    "# Last 543 for eval \n",
    "eval_data = dataset[\"train\"][9000:]\n",
    "\n",
    "# We'll use all of the validation data as test data. Do not train with this data. \n",
    "test_data = dataset[\"validation\"][:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820204e2-8d7d-47c9-be0c-d5d3c7489e24",
   "metadata": {},
   "source": [
    "### Convert to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c855f2f5-cc9c-41da-a030-f68e75e505cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv(csv_path, dataset_dict):\n",
    "    with open(csv_path, 'w', newline='') as csvfile:\n",
    "        writter = csv.writer(csvfile)\n",
    "        writter.writerow([\"text\", \"label\"])\n",
    "        for text, label in zip(dataset_dict[\"text\"], dataset_dict[\"label\"]):\n",
    "            writter.writerow([text, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb1bc951-5641-4c42-b402-95355c12b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = \"train.csv\"\n",
    "eval_csv = \"eval.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1606672-317e-45e7-a9f9-3f9fc4da12b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_csv(train_csv, train_data)\n",
    "generate_csv(eval_csv, eval_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba6fc3fa-3a65-472b-947b-6653805df5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_data[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a0a62-0484-4505-ad46-b2641fc1b806",
   "metadata": {},
   "source": [
    "0: Negative \n",
    "1: Positive \n",
    "2: Neutral "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966f1bca-890e-4a44-9146-5edeb4363fb5",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cb4d7ff-4dfc-464c-92eb-7b7a47cc1e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3783c353895e40439a214a4e26776aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ed3affdec24030b59da68b14764750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f11f3f2d70485aaca583e59cf048e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ca3cc3e36a4c25ab18721fdd2c2bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e982ebca7a8c4f6fbfecfe13b6947553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/24/2024 18:04:11 - INFO - happytransformer.happy_transformer -   Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "happy_tc = HappyTextClassification(\"DISTILBERT\", \"distilbert/distilbert-base-uncased\", num_labels=3) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1ce970-a616-49bd-9220-87d26496f8dd",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9777171-9dd1-4728-8a51-5d8736f1b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TCTrainArgs(num_train_epochs=1, eval_steps=0.1,  batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b247c065-d818-4545-93ca-c8ddca462199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d2a265b0af4e5fa86e72d2de7833d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffca515d42442d193adf11e524e32a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating eval split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/24/2024 18:04:12 - INFO - happytransformer.happy_transformer -   Tokenizing training data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e79d450a9841e6b05a74144db4da7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing data:   0%|          | 0/9000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "02/24/2024 18:04:14 - INFO - happytransformer.happy_transformer -   Tokenizing eval data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6207b58a57754e3bb9efff1f7b017b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing data:   0%|          | 0/543 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/24/2024 18:04:15 - INFO - happytransformer.happy_transformer -   Moving model to cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='563' max='563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [563/563 00:24, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.104000</td>\n",
       "      <td>1.087111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.752900</td>\n",
       "      <td>0.606862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>0.495191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.541200</td>\n",
       "      <td>0.480386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>0.494400</td>\n",
       "      <td>0.445683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>0.452400</td>\n",
       "      <td>0.420434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>0.449300</td>\n",
       "      <td>0.393757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>0.434800</td>\n",
       "      <td>0.377467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456</td>\n",
       "      <td>0.470500</td>\n",
       "      <td>0.378426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>513</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.361646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "happy_tc.train(input_filepath=train_csv, args=args, eval_filepath=eval_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063ac59f-33cb-4bb0-96fa-a5b6daca935b",
   "metadata": {},
   "source": [
    "## Sample Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7d620bc-7783-4aa4-b2fd-d88ba2bd53c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextClassificationResult(label='LABEL_0', score=0.9084067940711975)\n",
      "TextClassificationResult(label='LABEL_1', score=0.9253707528114319)\n",
      "TextClassificationResult(label='LABEL_2', score=0.9659663438796997)\n"
     ]
    }
   ],
   "source": [
    "output_negative = happy_tc.classify_text(\"Apple's stock just decreased\")\n",
    "print(output_negative) # We expect LABEL_0\n",
    "\n",
    "output_positive = happy_tc.classify_text(\"Apple's stock just increased\")\n",
    "print(output_positive) # We expect LABEL_1\n",
    "\n",
    "output_neutral = happy_tc.classify_text(\"Will apple continue to increase?\")\n",
    "print(output_neutral) # We expect LABEL_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d3271c-6cb7-44f3-b2c1-35c6e80e9be1",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8c350a9-884c-4e0d-b8f7-f9d47586b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our test dataset uses the following labels as ints: 0, 1, 2. \n",
    "# Our model outputs the strings \"LABEL_0\", \"LABEL_1\" and \"LABEL\"2. \n",
    "# We need to create a dictionary to map the labels from the test dataset to our model's outputs \n",
    "\n",
    "label_map = {    \n",
    "}\n",
    "for i in range(0, 3):\n",
    "    label_map[f\"LABEL_{i}\"] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa7c6cf7-2ba7-4ae7-9ec1-c6840d4961ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2}\n"
     ]
    }
   ],
   "source": [
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2215ecf8-6f8d-4d4b-86b5-05d1dfe476d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2388 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 2388/2388 [00:14<00:00, 163.42it/s]\n"
     ]
    }
   ],
   "source": [
    "correct = 0 \n",
    "total = len(test_data[\"label\"])\n",
    "for text, label in tqdm(zip(test_data[\"text\"], test_data[\"label\"]),  total=total):\n",
    "    output = happy_tc.classify_text(text)\n",
    "    if label_map[output.label] == label:\n",
    "        correct += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49803ac7-619c-42b7-9d20-e1de246d7330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2070\n",
      "2388\n"
     ]
    }
   ],
   "source": [
    "print(correct)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db033235-192f-4b79-a6ee-109077999151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 86.683%\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy: { round((correct/total)*100, 3)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
